{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ydHlMdh8Co7a"},"outputs":[],"source":["import random\n","from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n","from datasets import load_dataset, Dataset\n","import evaluate\n","import numpy as np\n","import wandb\n","from sklearn.ensemble import IsolationForest\n","import torch\n","\n","# Step 1: Initialize WandB and Load Dataset\n","wandb.init(project=\"Bert\", settings=wandb.Settings(init_timeout=120))\n","\n","dataset = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")\n","dataset = dataset.rename_column(\"label\", \"labels\")  # Rename for consistency\n","\n","# Poisoning attack remains untouched (no changes here)\n","\n","# Step 2: Preprocessing with Tokenizer\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","def preprocess_function(examples):\n","    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n","\n","# Apply the tokenizer\n","encoded_train = poisoned_train_data.map(preprocess_function, batched=True)\n","encoded_test = poisoned_test_data.map(preprocess_function, batched=True)\n","\n","# Set format for PyTorch\n","encoded_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","encoded_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","\n","# Step 3: Anomaly Detection using Isolation Forest (Optional)\n","def detect_anomalies(dataset, feature_column=\"input_ids\"):\n","    \"\"\"\n","    Use Isolation Forest to identify anomalies in the dataset based on embeddings.\n","\n","    Args:\n","    - dataset: PyTorch dataset.\n","    - feature_column: Column to use for detecting anomalies.\n","\n","    Returns:\n","    - Filtered dataset with anomalies removed.\n","    \"\"\"\n","    input_features = torch.stack([x[feature_column] for x in dataset])\n","    input_features_np = input_features.numpy()  # Convert to NumPy for sklearn\n","\n","    # Train Isolation Forest\n","    isolation_forest = IsolationForest(contamination=0.05, random_state=42)\n","    anomaly_labels = isolation_forest.fit_predict(input_features_np)\n","\n","    # Filter dataset to exclude anomalies\n","    clean_indices = [i for i, label in enumerate(anomaly_labels) if label == 1]\n","    return dataset.select(clean_indices)\n","\n","# Detect and remove anomalies from the training dataset\n","clean_train_dataset = detect_anomalies(encoded_train)\n","\n","# Step 4: Load Pretrained Model\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n","\n","# Step 5: Define Training Arguments with Regularization and Smoothing\n","training_args = TrainingArguments(\n","    output_dir=\"./results-poisoned-5\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    weight_decay=0.01,  # L2 Regularization\n","    logging_dir=\"./logs-poisoned-5\",\n","    logging_steps=10,\n","    save_steps=500,\n","    save_total_limit=2,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_accuracy\",\n","    label_smoothing_factor=0.1,  # Label smoothing for robustness\n",")\n","\n","# Step 6: Define Metrics\n","metric = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    accuracy = metric.compute(predictions=predictions, references=labels)\n","    return {\"eval_accuracy\": accuracy[\"accuracy\"]}\n","\n","# Step 7: Initialize Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=clean_train_dataset,\n","    eval_dataset=encoded_test,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Step 8: Train the Model\n","trainer.train()\n","\n","# Step 9: Evaluate the Model\n","evaluation_results = trainer.evaluate()\n","print(\"Evaluation Results:\", evaluation_results)\n","\n","# Step 10: Save the Model\n","model.save_pretrained(\"./bert-base-uncased-defended\")\n","tokenizer.save_pretrained(\"./bert-base-uncased-defended\")\n"]}]}